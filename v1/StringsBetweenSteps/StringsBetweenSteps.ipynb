{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.26.0\n",
      "Pipeline SDK-specific imports completed\n",
      "opendatasetspmworkspace\n",
      "opendatasetspmrg\n",
      "eastus2\n",
      "21d8f407-c4c4-452e-87a4-e609bfb86248\n",
      "Blobstore's name: workspaceblobstore\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "print(\"Pipeline SDK-specific imports completed\")\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
    "\n",
    "# Default datastore\n",
    "def_blob_store = ws.get_default_datastore() \n",
    "# The following call GETS the Azure Blob Store associated with your workspace.\n",
    "# Note that workspaceblobstore is **the name of this store and CANNOT BE CHANGED and must be used as is** \n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "print(\"Blobstore's name: {}\".format(def_blob_store.name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "cts = ws.compute_targets\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "    found = True\n",
    "    print('Found existing compute target.')\n",
    "    compute_target = cts[amlcompute_cluster_name]\n",
    "    \n",
    "if not found:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\", # for GPU, use \"STANDARD_NC6\"\n",
    "                                                                #vm_priority = 'lowpriority', # optional\n",
    "                                                                max_nodes = 4)\n",
    "\n",
    "    # Create the cluster.\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "    \n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "    compute_target.wait_for_completion(show_output = True, timeout_in_minutes = 10)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineRun, PipelineData, PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting string_from_pipeline_param.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile string_from_pipeline_param.py\n",
    "import argparse\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "parser = argparse.ArgumentParser(\"string_input\")\n",
    "parser.add_argument(\"--string\", type=str, help=\"sample string argument\")\n",
    "parser.add_argument(\"--output_path\", type=str, help=\"path to write output\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"Sample string pipeline paramater input: %s\" % args.string)\n",
    "\n",
    "print (f\"Checking if output_path: {args.output_path} is mounted: {os.path.isdir(args.output_path)}\")\n",
    "\n",
    "print (f\"Writing '{args.string}' to file {os.path.join(args.output_path,'string.txt')}\")\n",
    "\n",
    "with open(os.path.join(args.output_path,'string.txt'), 'w+') as text_file:\n",
    "    print(f\"{args.string}\", file=text_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting string_from_pipeline_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile string_from_pipeline_data.py\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser(\"string_input\")\n",
    "parser.add_argument(\"--input_path\", type=str, help=\"path to read input\")\n",
    "parser.add_argument(\"--output_path\", type=str, help=\"path to write output\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "filename = \"string.txt\"\n",
    "print (f\"reading file: {os.path.join(args.input_path, filename)})\n",
    "with open(os.path.join(args.input_path, filename), 'r') as handle:\n",
    "    string = handle.read()\n",
    "\n",
    "print (f\"Found in string.txt: {string}\")\n",
    "\n",
    "print (f\"Writing '{string}' to file {os.path.join(args.output_path,'string.txt')}\")\n",
    "with open(os.path.join(args.output_path,\"string.txt\"), \"w+\") as text_file:\n",
    "    print(f\"{string}\", file=text_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string_from_pipeline_data created\n"
     ]
    }
   ],
   "source": [
    "string_pipeline_param = PipelineParameter(name=\"input_string\", default_value='hello world')\n",
    "processed_data0 = PipelineData(\"processed_data0\", output_mode='mount')\n",
    "\n",
    "string_from_pipeline_param = PythonScriptStep(\n",
    "    name='string_from_pipeline_data',\n",
    "    script_name=\"string_from_pipeline_param.py\",\n",
    "    arguments=[\"--string\", string_pipeline_param, \"--output_path\", processed_data0],\n",
    "    outputs=[processed_data0],\n",
    "    compute_target=compute_target, \n",
    "    source_directory=\"./\")\n",
    "print(\"string_from_pipeline_data created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string_from_pipeline_data_1 created\n"
     ]
    }
   ],
   "source": [
    "processed_data1 = PipelineData(\"processed_data1\", output_mode='mount')\n",
    "\n",
    "string_from_pipeline_param_1 = PythonScriptStep(\n",
    "    name='string_from_pipeline_data_1',\n",
    "    script_name=\"string_from_pipeline_data.py\",\n",
    "    arguments=[\"--input_path\", processed_data0, \"--output_path\", processed_data1],\n",
    "    inputs=[processed_data0],\n",
    "    outputs=[processed_data1],\n",
    "    compute_target=compute_target, \n",
    "    source_directory=\"./\")\n",
    "print(\"string_from_pipeline_data_1 created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string_from_pipeline_data_2 created\n"
     ]
    }
   ],
   "source": [
    "processed_data2 = PipelineData(\"processed_data2\", output_mode='mount')\n",
    "\n",
    "string_from_pipeline_param_2 = PythonScriptStep(\n",
    "    name='string_from_pipeline_data_2',\n",
    "    script_name=\"string_from_pipeline_data.py\",\n",
    "    arguments=[\"--input_path\", processed_data1, \"--output_path\", processed_data2],\n",
    "    inputs=[processed_data1],\n",
    "    outputs=[processed_data2],\n",
    "    compute_target=compute_target, \n",
    "    source_directory=\"./\")\n",
    "print(\"string_from_pipeline_data_2 created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n",
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n",
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step string_from_pipeline_data [7626c0bf][177cd43b-81b8-4012-9b0f-e188a89c4874], (This step will run and generate new outputs)Created step string_from_pipeline_data_1 [f2120e66][9d969e55-b594-4e47-8b37-c4e2aa15046c], (This step will run and generate new outputs)\n",
      "Created step string_from_pipeline_data_2 [832618dd][dcec442a-ba89-4333-b90a-3a7f51ca06b7], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun 704d4eed-646d-464d-9426-94754bda7bde\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/704d4eed-646d-464d-9426-94754bda7bde?wsid=/subscriptions/21d8f407-c4c4-452e-87a4-e609bfb86248/resourcegroups/opendatasetspmrg/workspaces/opendatasetspmworkspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[string_from_pipeline_param,string_from_pipeline_param_1,string_from_pipeline_param_2])\n",
    "experiment = Experiment(ws, 'string-exp')\n",
    "#pipeline_run = experiment.submit(pipeline)\n",
    "pipeline_run_with_params = experiment.submit(pipeline,\n",
    "                                             pipeline_parameters={'input_string': 'hello python world'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
